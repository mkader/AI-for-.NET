## Add Logging
  1. Install Extensions Logging & console nuget package - Microsoft.Extensions.Logging, Microsoft.Extensions.Logging.Console
  1. Add  - using Microsoft.Extensions.DependencyInjection; using Microsoft.Extensions.Logging;
  1. Add logging services to the builder - builder.Services.AddLogging(b => b.AddConsole().SetMinimumLevel(LogLevel.Trace));
  2. Run
      ```console
      Q: Hello
      trce: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]
            ChatHistory: [{"Role":{"Label":"user"},"Items":[{"$type":"TextContent","Text":"Hello"}]}], Settings: {"temperature":1,"top_p":1,"presence_penalty":0,"frequency_penalty":0,"max_tokens":null,"stop_sequences":null,"results_per_prompt":1,"seed":null,"response_format":null,"chat_system_prompt":null,"token_selection_biases":null,"ToolCallBehavior":null,"User":null,"logprobs":null,"top_logprobs":null,"model_id":null}
      info: Microsoft.SemanticKernel.Connectors.OpenAI.OpenAIChatCompletionService[0]
            Prompt tokens: 8. Completion tokens: 9. Total tokens: 17.
      Hello! How can I help you today?
      Q:
      ```
      ![image](https://github.com/user-attachments/assets/aa604d7c-5c5e-4cdd-b242-cb7b710b038f)

```csharp
using System.Configuration;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using Microsoft.SemanticKernel.Connectors.OpenAI;

//Azure OpenAI settings
var deploymentName = ConfigurationManager.AppSettings["Azure_OpenAI_DeploymentName"];
var apiKey = ConfigurationManager.AppSettings["Azure_OpenAI_APIKey"];
var endPoint = ConfigurationManager.AppSettings["Azure_OpenAI_Endpoint"];

#pragma warning disable SKEXP0010 // Type is for evaluation purposes only and is subject to change or removal in future updates. Suppress this diagnostic to proceed.

var builder = Kernel.CreateBuilder();

builder.Services.AddLogging(b =>b.AddConsole().SetMinimumLevel(LogLevel.Trace));

var kernel = builder
                .AddAzureOpenAIChatCompletion(deploymentName, endPoint, apiKey) // add the Azure OpenAI chat completion service.
                .Build();

kernel.ImportPluginFromType<DemographicInfo>(); // add the DemographicInfo plugin to the kernel.

var chatService = kernel.GetRequiredService<IChatCompletionService>();

var settings = new OpenAIPromptExecutionSettings() { ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions };

ChatHistory chatHistory = [];

while (true)
{
    Console.Write("Q: ");
    chatHistory.AddUserMessage(Console.ReadLine()!);
    var response = await chatService.GetChatMessageContentAsync(chatHistory, settings, kernel);
    chatHistory.Add(response);
    Console.WriteLine(response);
}

internal class DemographicInfo
{
    [KernelFunction]
    public int GetAge(string name)
    {
        return name switch
        {
            "Mak" => 30,
            "Jane" => 25,
            _ => 0
        };
    }
}
```
